{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [u\"Football club Arsenal defeat local rivals this weekend.\",\n",
    "u\"Weekend football frenzy takes over London.\", u\"Bank open for takeover bids after losing millions.\", u\"London football clubs bid to move to Wembley stadium.\",\n",
    " u\"Arsenal bid 50 million pounds for striker Kane.\",\n",
    "u\"Financial troubles result in loss of millions for bank.\", u\"Western bank files for bankruptcy after financial losses.\", \n",
    "\"London football club is taken over by oil millionaire from Russia.\", u\"Banking on finances not working for Russia.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    text =[]\n",
    "    doc = nlp(document)\n",
    "    for w in doc:\n",
    "        if not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            text.append(w.lemma_)\n",
    "    texts.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['football', 'club', 'Arsenal', 'defeat', 'local', 'rival', 'weekend'], ['Weekend', 'football', 'frenzy', 'take', 'London'], ['bank', 'open', 'takeover', 'bid', 'lose', 'million'], ['London', 'football', 'club', 'bid', 'Wembley', 'stadium'], ['arsenal', 'bid', 'pound', 'striker', 'Kane'], ['financial', 'trouble', 'result', 'loss', 'million', 'bank'], ['western', 'bank', 'file', 'bankruptcy', 'financial', 'loss'], ['London', 'football', 'club', 'take', 'oil', 'millionaire', 'Russia'], ['banking', 'finance', 'work', 'Russia']]\n"
     ]
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(36 unique tokens: ['Arsenal', 'club', 'defeat', 'football', 'local']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arsenal': 0, 'club': 1, 'defeat': 2, 'football': 3, 'local': 4, 'rival': 5, 'weekend': 6, 'London': 7, 'Weekend': 8, 'frenzy': 9, 'take': 10, 'bank': 11, 'bid': 12, 'lose': 13, 'million': 14, 'open': 15, 'takeover': 16, 'Wembley': 17, 'stadium': 18, 'Kane': 19, 'arsenal': 20, 'pound': 21, 'striker': 22, 'financial': 23, 'loss': 24, 'result': 25, 'trouble': 26, 'bankruptcy': 27, 'file': 28, 'western': 29, 'Russia': 30, 'millionaire': 31, 'oil': 32, 'banking': 33, 'finance': 34, 'work': 35}\n"
     ]
    }
   ],
   "source": [
    "print( dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(3, 1), (7, 1), (8, 1), (9, 1), (10, 1)], [(11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)], [(1, 1), (3, 1), (7, 1), (12, 1), (17, 1), (18, 1)], [(12, 1), (19, 1), (20, 1), (21, 1), (22, 1)], [(11, 1), (14, 1), (23, 1), (24, 1), (25, 1), (26, 1)], [(11, 1), (23, 1), (24, 1), (27, 1), (28, 1), (29, 1)], [(1, 1), (3, 1), (7, 1), (10, 1), (30, 1), (31, 1), (32, 1)], [(30, 1), (33, 1), (34, 1), (35, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('.\\example.mm',corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4308818932262092), (1, 0.2154409466131046), (2, 0.4308818932262092), (3, 0.15902568651459398), (4, 0.4308818932262092), (5, 0.4308818932262092), (6, 0.4308818932262092)]\n",
      "[(3, 0.2184344336379748), (7, 0.29592528218102643), (8, 0.5918505643620529), (9, 0.5918505643620529), (10, 0.4051424990000138)]\n",
      "[(11, 0.25098743403237606), (12, 0.25098743403237606), (13, 0.5019748680647521), (14, 0.3436194281611727), (15, 0.5019748680647521), (16, 0.5019748680647521)]\n",
      "[(1, 0.29431054749542984), (3, 0.21724253258131512), (7, 0.29431054749542984), (12, 0.29431054749542984), (17, 0.5886210949908597), (18, 0.5886210949908597)]\n",
      "[(12, 0.24253562503633297), (19, 0.48507125007266594), (20, 0.48507125007266594), (21, 0.48507125007266594), (22, 0.48507125007266594)]\n",
      "[(11, 0.2615055248879333), (14, 0.35801943340074827), (23, 0.35801943340074827), (24, 0.35801943340074827), (25, 0.5230110497758667), (26, 0.5230110497758667)]\n",
      "[(11, 0.24434832234965204), (23, 0.33453001789363906), (24, 0.33453001789363906), (27, 0.4886966446993041), (28, 0.4886966446993041), (29, 0.4886966446993041)]\n",
      "[(1, 0.2645025265769199), (3, 0.1952400253294319), (7, 0.2645025265769199), (10, 0.3621225392416359), (30, 0.3621225392416359), (31, 0.5290050531538398), (32, 0.5290050531538398)]\n",
      "[(30, 0.3675524795645158), (33, 0.5369373566087501), (34, 0.5369373566087501), (35, 0.5369373566087501)]\n"
     ]
    }
   ],
   "source": [
    "for document in tfidf[corpus]:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['football', 'club', 'Arsenal', 'defeat', 'local', 'rival', 'weekend'], ['Weekend', 'football', 'frenzy', 'take', 'London'], ['bank', 'open', 'takeover', 'bid', 'lose', 'million'], ['London', 'football', 'club', 'bid', 'Wembley', 'stadium'], ['arsenal', 'bid', 'pound', 'striker', 'Kane'], ['financial', 'trouble', 'result', 'loss', 'million', 'bank'], ['western', 'bank', 'file', 'bankruptcy', 'financial', 'loss'], ['London', 'football', 'club', 'take', 'oil', 'millionaire', 'Russia'], ['banking', 'finance', 'work', 'Russia']]\n"
     ]
    }
   ],
   "source": [
    "bigram = models.Phrases(texts)\n",
    "texts = [bigram[line] for line in texts] #this steps should be done before creating dictionary or corpora\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "0\n",
      "Dictionary(0 unique tokens: [])\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))\n",
    "dictionary.filter_extremes(no_below=20,no_above=0.5)\n",
    "print(len(dictionary))\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_0 = nlp(u'Mathieu and I went to the park.')\n",
    "sent_1 = nlp(u'If Clement was asked to take out the garbage, he would refuse.')\n",
    "sent_2 = nlp(u'Baptiste was in charge of the refuse treatment center.')\n",
    "sent_3 = nlp(u'Marie took out her rather suspicious and fishy cat to go fish for fish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marie PROPN NNP\n",
      "took VERB VBD\n",
      "out ADP RP\n",
      "her PRON PRP\n",
      "rather ADV RB\n",
      "suspicious ADJ JJ\n",
      "and CCONJ CC\n",
      "fishy ADJ JJ\n",
      "cat NOUN NN\n",
      "to PART TO\n",
      "go VERB VB\n",
      "fish NOUN NN\n",
      "for ADP IN\n",
      "fish NOUN NN\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for token in sent_3:\n",
    "    print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132647\n"
     ]
    }
   ],
   "source": [
    "with open(\".\\data\\Freud.txt\") as f:\n",
    "    txt = f.read()\n",
    "\n",
    "print(len(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [x for x in Fr.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET 90\n",
      "NOUN 92\n",
      "ADP 85\n",
      "DET 90\n",
      "PROPN 96\n",
      "NOUN 92\n"
     ]
    }
   ],
   "source": [
    "for s in sents[0]:\n",
    "    print(s.pos_,s.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c6fbc1fa9f8e22016cc4c5b1d6cee697708750d816f9ec70f6447d44ab62434"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
